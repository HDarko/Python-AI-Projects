{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 1500 samples\n",
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 1.5569 - acc: 0.0873 - val_loss: 1.4913 - val_acc: 0.0840\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 1s 467us/step - loss: 1.4534 - acc: 0.1200 - val_loss: 1.3744 - val_acc: 0.3473\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 1s 415us/step - loss: 1.3401 - acc: 0.4467 - val_loss: 1.2865 - val_acc: 0.5013\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 1s 423us/step - loss: 1.2771 - acc: 0.5000 - val_loss: 1.2602 - val_acc: 0.5007\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 1s 454us/step - loss: 1.2540 - acc: 0.5000 - val_loss: 1.2424 - val_acc: 0.5007\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 1s 433us/step - loss: 1.2374 - acc: 0.5000 - val_loss: 1.2297 - val_acc: 0.5007\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 1s 427us/step - loss: 1.2258 - acc: 0.5000 - val_loss: 1.2216 - val_acc: 0.5007\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 1s 423us/step - loss: 1.2184 - acc: 0.5000 - val_loss: 1.2170 - val_acc: 0.5007\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 1s 428us/step - loss: 1.2145 - acc: 0.5000 - val_loss: 1.2148 - val_acc: 0.5007\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 1s 428us/step - loss: 1.2111 - acc: 0.5000 - val_loss: 1.2130 - val_acc: 0.5007\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 1s 423us/step - loss: 1.2086 - acc: 0.5000 - val_loss: 1.2117 - val_acc: 0.5007\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 1s 430us/step - loss: 1.2071 - acc: 0.5000 - val_loss: 1.2111 - val_acc: 0.5007\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 1s 434us/step - loss: 1.2052 - acc: 0.5000 - val_loss: 1.2099 - val_acc: 0.5007\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 1s 403us/step - loss: 1.2038 - acc: 0.5000 - val_loss: 1.2095 - val_acc: 0.5007\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 1s 432us/step - loss: 1.2017 - acc: 0.5000 - val_loss: 1.2096 - val_acc: 0.5007\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 1s 410us/step - loss: 1.2007 - acc: 0.5000 - val_loss: 1.2088 - val_acc: 0.5000\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 1s 431us/step - loss: 1.1989 - acc: 0.5000 - val_loss: 1.2090 - val_acc: 0.5000\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 1s 500us/step - loss: 1.1975 - acc: 0.5000 - val_loss: 1.2087 - val_acc: 0.5000\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 1s 536us/step - loss: 1.1958 - acc: 0.5000 - val_loss: 1.2083 - val_acc: 0.4993\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 1s 505us/step - loss: 1.1935 - acc: 0.5000 - val_loss: 1.2079 - val_acc: 0.4993\n",
      "1500/1500 [==============================] - 0s 184us/step\n",
      "When tested on the remaining half of the training data the accuracy was 0.4993333338101705\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 20 random moves\n",
      "Puzzle state: 297451386_ab\n",
      "For A* using heuristic <function MisplacedTile at 0x7f0397cdc6a8>\n",
      "Length of Solution 88\n",
      "Length of Closed list 1435\n",
      "Length of Open list 1116\n",
      "<function MisplacedTile at 0x7f0397cdc6a8> (88, 1435, 1116)\n",
      "For A* using heuristic <function TileRowCol at 0x7f0397cdc730>\n",
      "Length of Solution 70\n",
      "Length of Closed list 265\n",
      "Length of Open list 188\n",
      "<function TileRowCol at 0x7f0397cdc730> (70, 265, 188)\n",
      "For A* using heuristic <function Nilson at 0x7f0397cdc950>\n",
      "Length of Solution 72\n",
      "Length of Closed list 1267\n",
      "Length of Open list 991\n",
      "<function Nilson at 0x7f0397cdc950> (72, 1267, 991)\n",
      "For A* using NN heuristic\n",
      "Length of Solution 148\n",
      "Length of Closed list 1597\n",
      "Length of Open list 1326\n",
      "(148, 1597, 1326)\n",
      "Puzzle state: 1923a58b_674\n",
      "For A* using heuristic <function MisplacedTile at 0x7f0397cdc6a8>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3776ba8667d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;31m#TestingAgent(\"11final8.txt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"For 20 random moves\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m \u001b[0mTestingAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"11final20.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;31m#print(\"For 40 random moves\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;31m#TestingAgent(\"11final40.txt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3776ba8667d9>\u001b[0m in \u001b[0;36mTestingAgent\u001b[0;34m(file, numofStates)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Puzzle state: \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAgentNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0msd\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3776ba8667d9>\u001b[0m in \u001b[0;36mAgent\u001b[0;34m(state, size, func)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclosedList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# imported modules for neural network\n",
    "from keras import models\n",
    "from keras import layers\n",
    "#from keras.layers import Flatten\n",
    "from keras import optimizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.datasets import reuters\n",
    "from keras.layers import Embedding\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from TrainingAgent import *\n",
    "\n",
    "#The code for training the Neural Network, along with the heuristics implementation comes from\n",
    "#TrainingAgent\n",
    "\n",
    "dynamicWeight=3\n",
    "import heapq\n",
    "###############################################TESTING AGENT IMPLEMENTATION###################################################\n",
    "#The Open List is created as a piority queue so the node with the lowest f(n) is always removed when pop() is used\n",
    "class PriorityQueue:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._queue = []\n",
    "        self._index = 0\n",
    "        self.size=0\n",
    " \n",
    "    def push(self,node):\n",
    "        heapq.heappush(self._queue, (node.h, self._index, node))\n",
    "        self._index += 1\n",
    "        self.size+=1\n",
    " \n",
    "    \n",
    "    def pop(self):\n",
    "        self.size-=1\n",
    "        return heapq.heappop(self._queue)[-1]\n",
    "    \n",
    "# Node class that contain a specific puzzle board state, the node's parent,\n",
    "#the location of the blank in the parent , the current cost f(n) of the node\n",
    "\n",
    "    \n",
    "class Node():\n",
    "\n",
    "    def __init__(self,state,parent=None,lastblankloc=-1,h=0):\n",
    "        self.parent = parent\n",
    "        self.state=state\n",
    "        if(parent==None):\n",
    "            self.g=0\n",
    "        else:\n",
    "            self.g=parent.g+5\n",
    "        self.h = h\n",
    "        self.prevblank=lastblankloc\n",
    "        self.f = self.g+h\n",
    "\n",
    "# a wally to check if the node has the same state as the other which is a state. \n",
    "    def __eq__(self,other):\n",
    "        return (self.state == other)\n",
    "\n",
    "# the main function\n",
    "# for each state in the input file the function tries to solve the puzzle\n",
    "#using each of the heuristics in hList then the Neural Network heuristic.\n",
    "#currently it solves n states per file then break\n",
    "def TestingAgent(file,numofStates):\n",
    "    hList=[MisplacedTile,TileRowCol,Nilson]\n",
    "    #LinearCon\n",
    "    inputf=open(file,\"r\")\n",
    "    sd=0\n",
    "    for state in inputf:\n",
    "        if (sd==numofStates):\n",
    "            return\n",
    "        else:\n",
    "            state=state.strip('\\n')\n",
    "            size=len(state)-1\n",
    "            print(\"Puzzle state: \" +state)\n",
    "            for func in hList:\n",
    "                print(func,Agent(state,size,func))\n",
    "            print(AgentNN(state,size,\"func\"))\n",
    "            sd+=1\n",
    "\n",
    "\n",
    "#An A* algorithm that tries to solve a puzzle with the given heuristic func.\n",
    "def Agent(state,size,func):\n",
    "    if (size==11):\n",
    "        goal=\"123456789ab_\"\n",
    "    if(size==15):\n",
    "        goal=\"123456789abcdef_\"\n",
    "    startN=Node(state,None)\n",
    "    openList=PriorityQueue()\n",
    "    closedList=[]\n",
    "    sd=0\n",
    "    openList.push(startN)\n",
    "    lastmov=state.index(\"_\")\n",
    "    #loop\n",
    "    print(\"For A* using heuristic\",func)\n",
    "    while (openList.size!=0):\n",
    "        curNode=openList.pop()\n",
    "        \n",
    "        closedList.append(curNode)\n",
    "        \n",
    "        #if node is goal\n",
    "        if(curNode==goal):\n",
    "            path=[]\n",
    "            while(curNode.parent!=None):\n",
    "                path.append(curNode.state)\n",
    "                curNode = curNode.parent\n",
    "            \n",
    "            print(\"Length of Solution\",len(path))\n",
    "            print(\"Length of Closed list\",len(closedList))\n",
    "            print(\"Length of Open list\",openList.size)\n",
    "            return(len(path),len(closedList),openList.size)\n",
    "        #Generate children nodes instead\n",
    "        else:\n",
    "            sd+=1\n",
    "        \n",
    "            moves=Moves(curNode.state,size,lastmov)\n",
    "            lastmov=curNode.state.index(\"_\") \n",
    "            children = []\n",
    "            for move in moves:\n",
    "                newState=MoveAction(curNode.state,move)\n",
    "                heur=func(newState,size)\n",
    "                child=Node(newState,curNode,lastmov,heur)\n",
    "                children.append(child)\n",
    "            #print(\"Parent is: \"+ curNode.state)\n",
    "            for child in children:\n",
    "                x=1\n",
    "                for mem in closedList:\n",
    "                    if (child==mem.state):\n",
    "                        x=0\n",
    "                for mem in sorted(openList._queue):\n",
    "                \n",
    "                    #print(\"comparing child: \"+child.state+\" against \"+mem[2].state)\n",
    "                   # print(\"Result is: \"+ str(child == mem[2].state))\n",
    "                    if ((child == mem[2].state) and (child.g > mem[2].g)):\n",
    "                  \n",
    "                        x=0\n",
    "                if(x==1):\n",
    "                    # if child node's state does not already exist in either lists\n",
    "                    # then add to OpenQueue\n",
    "                    #these extra commented features help track movement of A during testing\n",
    "                   # print(\"Child State: \"+ str(child.state))\n",
    "                    #print(\"H Cost: \"+ str(child.h))\n",
    "                    #print(\"child level:  \"+ str(sd))\n",
    "                    openList.push(child)\n",
    "                #print(\"child enters: \"+ child.state)\n",
    "                #print(\"child level:  \"+ str(sd))\n",
    "                #print(\"Openlist is: \"+ str(sorted(openList._queue)))\n",
    "                #print(\"Closedlist is: \"+  str(closedList))\n",
    "              \n",
    "             \n",
    "                       \n",
    "                \n",
    "#An A* algorithm that tries to solve a puzzle with the Neural Network Heuristic.\n",
    "#Prints out the length of solution, and size of the Open and Closed List if one \n",
    "#is found\n",
    "def AgentNN(state,size,func):\n",
    "    if (size==11):\n",
    "        goal=\"123456789ab_\"\n",
    "    if(size==15):\n",
    "        goal=\"123456789abcdef_\"\n",
    "    startN=Node(state,None)\n",
    "    openList=PriorityQueue()\n",
    "    closedList=[]\n",
    "    sd=0\n",
    "    openList.push(startN)\n",
    "    lastmov=state.index(\"_\")\n",
    "    #loop\n",
    "    print(\"For A* using NN heuristic\")\n",
    "    while (openList.size!=0):\n",
    "        curNode=openList.pop()\n",
    "        closedList.append(curNode)\n",
    "        #if node is goal\n",
    "        if(curNode==goal):\n",
    "            path=[]\n",
    "            while(curNode.parent!=None):\n",
    "                path.append(curNode.state)\n",
    "               \n",
    "                curNode = curNode.parent\n",
    "            print(\"Length of Solution\",len(path))\n",
    "            print(\"Length of Closed list\",len(closedList))\n",
    "            print(\"Length of Open list\",openList.size)   \n",
    "            return(len(path),len(closedList),openList.size)\n",
    "        #Generate children instead\n",
    "        else:\n",
    "            #first create a vector heuristics to give the heuristic\n",
    "            # along with the list of legal moves\n",
    "            sd+=1         \n",
    "            moves=Moves(curNode.state,size,lastmov)\n",
    "            blank=curNode.state.index(\"_\") \n",
    "            sub1=MisplacedTile(curNode.state,size)\n",
    "            sub2=TileRowCol(curNode.state,size)\n",
    "            sub3=Nilson(curNode.state,size)\n",
    "            vector=[sub1,sub2,sub3]\n",
    "            # bestmoves returns a list of legal moves \n",
    "            #sorted by the neural network heuristic from most likely to worst candidate \n",
    "            bestmoves=NNm(vector,blank,moves)\n",
    "            lastmov=curNode.state.index(\"_\")\n",
    "            children = [] \n",
    "            # create the child nodes per legal move and assign the heuristic cost h(n)\n",
    "            # as a result of the neural network heuristic\n",
    "            for move in bestmoves:\n",
    "                newState=MoveAction(curNode.state,move)\n",
    "                heur=((sum(vector))/len(vector))+(dynamicWeight*(bestmoves.index(move)))\n",
    "                child=Node(newState,curNode,lastmov,heur)\n",
    "                children.append(child)\n",
    "            #print(\"Parent is: \"+ curNode.state)\n",
    "            for child in children:\n",
    "                x=1\n",
    "                for mem in closedList:\n",
    "                    if (child==mem.state):\n",
    "                        x=0\n",
    "                for mem in sorted(openList._queue):\n",
    "                \n",
    "                    #print(\"comparing child: \"+child.state+\" against \"+mem[2].state)\n",
    "                   # print(\"Result is: \"+ str(child == mem[2].state))\n",
    "                    if ((child == mem[2].state) and (child.g > mem[2].g)):\n",
    "                  \n",
    "                        x=0\n",
    "                if(x==1):\n",
    "                    \n",
    "                    openList.push(child)\n",
    "                 # if child node's state does not already exist in either lists\n",
    "                # then add to OpenQueue\n",
    "                #these extra commented features help track movement of A during testing\n",
    "                #print(\"child enters: \"+ child.state)\n",
    "                #print(\"child level:  \"+ str(sd))\n",
    "                #print(\"Openlist is: \"+ str(sorted(openList._queue)))\n",
    "                #print(\"Closedlist is: \"+  str(closedList))\n",
    "#     \n",
    "#Takes a vector of heuristic values for a specific state\n",
    "#then takes the predicted probabilties of each move being the \n",
    "#the expected move as ouputed by the neural network\n",
    "#then sorts the moves based on these predictions from highest to lowest.\n",
    "#then removes the illegal moves and returns the sorted moves as a list.\n",
    "def NNm(vector,blank,moves):\n",
    "    #print(model.predict(np.array(vector).reshape((1,3))))\n",
    "    prob=model.predict(np.array(vector).reshape((1,3)))\n",
    "    probl=list(prob[0])\n",
    "    p=[probl.index(x) for x in sorted(probl, reverse=True)]\n",
    "    result=[]\n",
    "    for label in p:\n",
    "        if ((label==1)):\n",
    "            if ((blank-1) in moves):\n",
    "                result.append((blank-1))\n",
    "                \n",
    "        if ((label==3)):\n",
    "            if ((blank+1) in moves):\n",
    "                result.append((blank+1))\n",
    "             \n",
    "        if ((label==2)):\n",
    "            if ((blank-4) in moves):\n",
    "                result.append((blank-4))\n",
    "         \n",
    "        if ((label==0)):\n",
    "            if ((blank+4) in moves):\n",
    "                result.append((blank+4))\n",
    "\n",
    "    return (result)    \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "#Function that takes the input board state, \n",
    "#the location of blank in a previous state before the move that generated this state\n",
    "# then returns a list of posible indexs or tile postions the blank can move to.  \n",
    "# yet also prevent the move that undo's the last move from being part of the list\n",
    "#ie go left in previous state then right in this state\n",
    "    \n",
    "def Moves(state,size,lastLoc):\n",
    "    moves=[]\n",
    "    blank=state.index(\"_\")\n",
    "    if(size==11):\n",
    "        #if blank can move right then get the tuple for that move\n",
    "        #maybe change to even number with division\n",
    "        if(((blank+1)!=4) and ((blank+1)!=8) and ((blank+1)!=12)):\n",
    "            #moves.append((blank,state[blank+1]))\n",
    "            moves.append(blank+1)\n",
    "        #if the blank can move left get the tuple for that move\n",
    "        if(((blank-1)!=-1) and ((blank-1)!=3)and((blank-1)!=7)):\n",
    "            #moves.append((blank,state[blank-1])) \n",
    "            moves.append(blank-1)\n",
    "        #if the blank can move up then get the tuple for that move\n",
    "        if((blank)>=4):\n",
    "            #moves.append((blank,state[blank-4]))\n",
    "            moves.append(blank-4)\n",
    "        #if the blank can move down then get tuple for that move\n",
    "        if((blank)<8):\n",
    "           #moves.append((blank,state[blank+4]))\n",
    "           moves.append(blank+4)\n",
    "        if(lastLoc in moves):\n",
    "            moves.remove(lastLoc)\n",
    "        return moves       \n",
    "    \n",
    "#Output the resulting new state generated from an input state and move   \n",
    "def MoveAction(state,move):\n",
    "    newstate=list(state)\n",
    "    blank=newstate.index(\"_\")\n",
    "    newstate[blank],newstate[move]=newstate[move],newstate[blank]\n",
    "    return \"\".join(newstate)\n",
    "\n",
    "#print the current board\n",
    "def Board(state):\n",
    "    if (len(state)==12):\n",
    "        print(state[0:4])\n",
    "        print (state[4:8])\n",
    "        print (state[8:12])\n",
    "    if (len(state)==16):\n",
    "        print(state[0:4])\n",
    "        print (state[4:8])\n",
    "        print (state[8:12])\n",
    "        print (state[12:16])\n",
    " \n",
    "\n",
    "\n",
    " ####################################NEURAL NETWORK IMPLEMENTATION FOR NEURAL NETWORK HEURISTIC###############################\n",
    "#Index for moves [0 1 2 3] with 2-Up,0-Down,1-Left,3-Right\n",
    "\n",
    "#The training and evaluation for the neural network is here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Creates a new Numppty Array from the file to be used\n",
    "#to train the neural network\n",
    "def toArray(output1):\n",
    "    output11=open(output1,\"r\")\n",
    "    out=[x.strip() for x in output11.readlines()]\n",
    "    out=[x.strip('][').split(',')for x in out]\n",
    "    out=[list(map(int, x)) for x in out ]\n",
    "    return np.array(out)\n",
    "\n",
    "\n",
    "#Creates a array of labels that can be catagorized \n",
    "#to make them ready for the Neural Network\n",
    "\n",
    "def labels(array):\n",
    "    out=[x[0] for x in array]\n",
    "    return np.asarray(out).astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################################################################################\n",
    "#After running the Heuristics function for the given file \n",
    "#The  newly created 11DataSets and 11Labels will be used to train \n",
    "#the Neural Network\n",
    "#The results of the training will be displayed on screen then\n",
    "#once TestingAgent is called the results of A* solving a file with\n",
    "#each heuristic will displayed if a solution is found.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Heuristics(\"11puzzles.txt\",11)\n",
    "\n",
    "#Enter the name of the file with the training data and  \n",
    "\n",
    "\n",
    "eleven_output=toArray(\"11DataSet.txt\")\n",
    "#fifteen_output=toArray(\"15DataSet.txt\")\n",
    "#fifteen_label=to_categorical(labels(toArray(\"15DataLabel.txt\")))\n",
    "eleven_label=to_categorical(labels(toArray(\"11DataLabel.txt\")))\n",
    "\n",
    "#print((fifteen_output[0]))\n",
    "#print(len(fifteen_label))\n",
    "#print(eleven_output.dtype)\n",
    "#print(eleven_label)\n",
    "#print(eleven_label.shape)\n",
    "\n",
    "el_val=eleven_output[0:1500]\n",
    "elp_val=eleven_output[1500:]\n",
    "el_lab=eleven_label[0:1500]\n",
    "elp_lab=eleven_label[1500:]\n",
    "\n",
    "#Copied from disfferent source\n",
    "\"\"\"The Embedding layer is defined as the first hidden layer of a network. It must specify 3 arguments:\n",
    "\n",
    "It must specify 3 arguments:\n",
    "\n",
    "    input_dim: This is the size of the vocabulary in the text data. For example\n",
    "    , if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\n",
    "    output_dim: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\n",
    "    input_length: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000.\n",
    "\n",
    "For example, below we define an Embedding layer with a vocabulary of 200 (e.g. integer encoded words from 0 to 199, inclusive), a vector space of 32 dimensions in which words will be embedded, and input documents that have 50 words each.\n",
    "e = Embedding(200, 32, input_length=50)\n",
    "1\n",
    "\t\n",
    "e = Embedding(200, 32, input_length=50)\n",
    "model=models.Sequential()\"\"\"\n",
    "\n",
    "#Since each state is distinct like words in a dictionary we can use the Embeding layer.\n",
    "#The values in the vectors are of range 0-120 so the size is 121\n",
    "##################################################NNEURAL NETWORK ARCHITECTURE################################################\n",
    "\n",
    "model=models.Sequential()\n",
    "model.add(layers.Embedding(121,1500,input_length=3))\n",
    "model.add(layers.LSTM(24))\n",
    "#model.add(layers.LSTM(1500,return_sequences=True))\n",
    "#model.add(layers.GRU(1500))\n",
    "\n",
    "#model.add(layers.Flatten())\n",
    "#exponential-511333333492279\n",
    "             #'hard_sigmoid'-0.5193333331743876,0.520666666507721\n",
    "#sigmoid\n",
    "model.add(layers.Dense(8,activation='hard_sigmoid'))\n",
    "model.add(layers.Dense(4,activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history=model.fit(el_val,el_lab,epochs=20,batch_size=500,validation_data=(elp_val,elp_lab))\n",
    "print(\"When tested on the remaining half of the training data the accuracy was\", model.evaluate(elp_val,elp_lab)[1])\n",
    "\n",
    "#Prints a \n",
    "acc=history.history['acc']\n",
    "val_acc=history.history['val_acc']\n",
    "loss=history.history['loss']\n",
    "epochs=range(1,len(loss)+1)\n",
    "plt.plot(epochs,acc,'bo',label='Training acc')\n",
    "plt.plot(epochs,val_acc,'b',label='Validation acc')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"For 5 random moves\")\n",
    "TestingAgent(\"11final5.txt\",5)\n",
    "print(\"For 20 random moves\")\n",
    "TestingAgent(\"11final20.txt\",5)\n",
    "#print(\"For 40 random moves\")\n",
    "#TestingAgent(\"11final40.txt\")\n",
    "#print(\"For 42 random moves\")\n",
    "#TestingAgent(\"11final42.txt\")\n",
    "#print(\"For 45 random moves\")\n",
    "#TestingAgent(\"11final45.txt\")\n",
    "#print(\"For 30 random moves\")\n",
    "#TestingAgent(\"11final30.txt\")\n",
    "\n",
    "\n",
    "#AgentNN(\"1_24673859ab\",11,\"func\")\n",
    "#AgentNN(\"_14b623957a8\",11,\"func\")\n",
    "#Agent(\"1_24673859ab\",11,LinearCon)\n",
    "#LinearCon(\"1_24673859ab\",11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
